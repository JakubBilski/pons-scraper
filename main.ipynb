{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_plural_form(word, suffix):\n",
    "    len_w = len(word)\n",
    "    len_s = len(suffix)\n",
    "    best_offset = len_w\n",
    "    best_offset_score = 1\n",
    "    for offset in range(max(0, len_w - len_s), len_w):\n",
    "        offset_score = sum([word[offset+i] == suffix[i] for i in range(min(len_s, len_w-offset))])\n",
    "        if offset_score > best_offset_score:\n",
    "            best_offset = offset\n",
    "            best_offset_score = offset_score\n",
    "    return 'die '+ word[:best_offset] + suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_noun(word_romhead, word_h2):\n",
    "    translation = ' '.join([\n",
    "        a.text for a in word_romhead.find(class_='target').findAll('a', recursive=False)\n",
    "    ]).replace('  ', ' ')\n",
    "    if \"r.m.\" in word_h2.text:\n",
    "        article = \"der\"\n",
    "    elif \"r.ż.\" in word_h2.text:\n",
    "        article = \"die\"\n",
    "    else:\n",
    "        article = \"das\"\n",
    "    word_div = [\n",
    "        div for div in word_romhead.findAll(class_='translations')\n",
    "    ][0]\n",
    "    word = ' '.join([\n",
    "        a.text for a in word_div.findAll(\n",
    "            class_='source'\n",
    "        )[0].findAll(['a', 'strong'])\n",
    "    ])\n",
    "    flexion_text = word_h2.find(class_='flexion').text\n",
    "    plural_suffix = flexion_text[flexion_text.index(',')+2:-1]\n",
    "    if plural_suffix[0] == '‑':\n",
    "        plural_form = find_best_plural_form(word, plural_suffix[1:])\n",
    "    elif 'bez l.mn.' in plural_suffix:\n",
    "        plural_form = '-'\n",
    "    else:\n",
    "        plural_form = 'die ' + plural_suffix\n",
    "    zwroty_divs = [\n",
    "        div for div\n",
    "        in word_romhead.findAll(class_='translations')\n",
    "        if 'zwroty' in div.find('h3').text\n",
    "    ]\n",
    "    if len(zwroty_divs) == 0:\n",
    "        return translation, f\"{article} {word}, {plural_form}\\n\"\n",
    "    else:\n",
    "        zwrot = ' '.join([\n",
    "            a.text for a in zwroty_divs[0].findAll(\n",
    "                class_='source'\n",
    "            )[0].findAll('span')[0].findAll(['a', 'strong'])\n",
    "        ])\n",
    "        zwrot = zwrot.replace('  ', ' ')\n",
    "\n",
    "        zwrot_translation = ' '.join([\n",
    "            a.text for a in zwroty_divs[0].findAll(\n",
    "                class_='target'\n",
    "            )[0].findAll('a')\n",
    "        ])\n",
    "        zwrot_translation = zwrot_translation.replace('  ', ' ')\n",
    "        return translation, f\"{article} {word}, {plural_form}\\n\\n{zwrot}\\n({zwrot_translation})\\n\"\n",
    "\n",
    "\n",
    "def parse_verb(word_romhead, word_h2):\n",
    "    translation = ' '.join([a.text for a in word_romhead.find(class_='target').findAll('a', recursive=False)]).replace('  ', ' ')\n",
    "    word_div = [\n",
    "        div for div in word_romhead.findAll(class_='translations')\n",
    "    ][0]\n",
    "    word = ' '.join([\n",
    "        a.text for a in word_div.findAll(\n",
    "            class_='source'\n",
    "        )[0].findAll(['a', 'strong'])\n",
    "    ])\n",
    "    return translation, word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_page_as_word_romheads(word):\n",
    "    url = f\"https://pl.pons.com/t%C5%82umaczenie/niemiecki-polski/{word}\"\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "    except:\n",
    "        print(f\"Unable to get {word}, site {url} doesn't respond\")\n",
    "        return None, None\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    word_romheads = soup.findAll(class_=\"rom first\")\n",
    "    return word_romheads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debug below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = ' '.join([\n",
    "    a.text for a in word_div.findAll(\n",
    "        class_='source'\n",
    "    )[0].findAll(['a', 'strong'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'findAll'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m word_romhead \u001b[39m=\u001b[39m word_romheads[\u001b[39m1\u001b[39m]\n\u001b[0;32m      2\u001b[0m word_h2 \u001b[39m=\u001b[39m word_romhead\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mh2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m translation \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([a\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m word_romhead\u001b[39m.\u001b[39;49mfind(class_\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mfindAll(\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, recursive\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)])\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m  \u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m word \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\n\u001b[0;32m      5\u001b[0m     a\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m word_div\u001b[39m.\u001b[39mfindAll(\n\u001b[0;32m      6\u001b[0m         class_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msource\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      7\u001b[0m     )[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mfindAll([\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstrong\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      8\u001b[0m ])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'findAll'"
     ]
    }
   ],
   "source": [
    "word_romhead = word_romheads[1]\n",
    "word_h2 = word_romhead.find(\"h2\")\n",
    "translation = ' '.join([a.text for a in word_romhead.find(class_='target').findAll('a', recursive=False)]).replace('  ', ' ')\n",
    "word = ' '.join([\n",
    "    a.text for a in word_div.findAll(\n",
    "        class_='source'\n",
    "    )[0].findAll(['a', 'strong'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 20\u001b[0m\n\u001b[0;32m     12\u001b[0m word_div \u001b[39m=\u001b[39m [\n\u001b[0;32m     13\u001b[0m     div \u001b[39mfor\u001b[39;00m div \u001b[39min\u001b[39;00m word_romhead\u001b[39m.\u001b[39mfindAll(class_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtranslations\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m ][\u001b[39m0\u001b[39m]\n\u001b[0;32m     15\u001b[0m word \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\n\u001b[0;32m     16\u001b[0m     a\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m word_div\u001b[39m.\u001b[39mfindAll(\n\u001b[0;32m     17\u001b[0m         class_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msource\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     18\u001b[0m     )[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mfindAll([\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstrong\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     19\u001b[0m ])\n\u001b[1;32m---> 20\u001b[0m flexion_text \u001b[39m=\u001b[39m word_h2\u001b[39m.\u001b[39;49mfind(class_\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mflexion\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mtext\n\u001b[0;32m     21\u001b[0m plural_suffix \u001b[39m=\u001b[39m flexion_text[flexion_text\u001b[39m.\u001b[39mindex(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m+\u001b[39m\u001b[39m2\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     22\u001b[0m \u001b[39mif\u001b[39;00m plural_suffix[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m‑\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "word_romhead = word_romheads[0]\n",
    "word_h2 = word_romhead.find(\"h2\")\n",
    "translation = ' '.join([\n",
    "        a.text for a in word_romhead.find(class_='target').findAll('a', recursive=False)\n",
    "    ]).replace('  ', ' ')\n",
    "if \"r.m.\" in word_h2.text:\n",
    "    article = \"der\"\n",
    "elif \"r.ż.\" in word_h2.text:\n",
    "    article = \"die\"\n",
    "else:\n",
    "    article = \"das\"\n",
    "word_div = [\n",
    "    div for div in word_romhead.findAll(class_='translations')\n",
    "][0]\n",
    "word = ' '.join([\n",
    "    a.text for a in word_div.findAll(\n",
    "        class_='source'\n",
    "    )[0].findAll(['a', 'strong'])\n",
    "])\n",
    "flexion_text = word_h2.find(class_='flexion').text\n",
    "plural_suffix = flexion_text[flexion_text.index(',')+2:-1]\n",
    "if plural_suffix[0] == '‑':\n",
    "    plural_form = find_best_plural_form(word, plural_suffix[1:])\n",
    "elif 'bez l.mn.' in plural_suffix:\n",
    "    plural_form = '-'\n",
    "else:\n",
    "    plural_form = 'die ' + plural_suffix\n",
    "zwroty_divs = [\n",
    "    div for div\n",
    "    in word_romhead.findAll(class_='translations')\n",
    "    if 'zwroty' in div.find('h3').text\n",
    "]\n",
    "if len(zwroty_divs) == 0:\n",
    "    return translation, f\"{article} {word}, {plural_form}\\n\"\n",
    "else:\n",
    "    zwrot = ' '.join([\n",
    "        a.text for a in zwroty_divs[0].findAll(\n",
    "            class_='source'\n",
    "        )[0].findAll('span')[0].findAll(['a', 'strong'])\n",
    "    ])\n",
    "    zwrot = zwrot.replace('  ', ' ')\n",
    "\n",
    "    zwrot_translation = ' '.join([\n",
    "        a.text for a in zwroty_divs[0].findAll(\n",
    "            class_='target'\n",
    "        )[0].findAll('a')\n",
    "    ])\n",
    "    zwrot_translation = zwrot_translation.replace('  ', ' ')\n",
    "    return translation, f\"{article} {word}, {plural_form}\\n\\n{zwrot}\\n({zwrot_translation})\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_card(word_romheads):\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    for word_romhead in word_romheads:\n",
    "        if \"ytkownika\" in word_romhead.text:\n",
    "            # skip user-created translations\n",
    "            continue\n",
    "        word_h2 = word_romhead.find(\"h2\")\n",
    "        word_class = word_h2.find(class_='wordclass').text\n",
    "        if 'CZ.' in word_class:\n",
    "            question, answer = parse_verb(word_romhead, word_h2)\n",
    "        elif 'RZ.' in word_class:\n",
    "            question, answer = parse_noun(word_romhead, word_h2)\n",
    "        else:\n",
    "            continue\n",
    "        questions.append(question)\n",
    "        answers.append(answer)\n",
    "        if len(questions) > 1:\n",
    "            break\n",
    "\n",
    "    front = ''\n",
    "    reverse = ''\n",
    "\n",
    "    for i, q in enumerate(questions):\n",
    "        front += f'{i+1}: {q}\\n'\n",
    "\n",
    "    for i, a in enumerate(answers):\n",
    "        reverse += f'{a}\\n\\n'\n",
    "    \n",
    "    return front, reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_romheads = download_page_as_word_romheads('frish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'findAll'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m front, reverse \u001b[39m=\u001b[39m create_card(word_romheads)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(front)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-----\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[43], line 12\u001b[0m, in \u001b[0;36mcreate_card\u001b[1;34m(word_romheads)\u001b[0m\n\u001b[0;32m     10\u001b[0m word_class \u001b[39m=\u001b[39m word_h2\u001b[39m.\u001b[39mfind(class_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mwordclass\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mtext\n\u001b[0;32m     11\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mCZ.\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m word_class:\n\u001b[1;32m---> 12\u001b[0m     question, answer \u001b[39m=\u001b[39m parse_verb(word_romhead, word_h2)\n\u001b[0;32m     13\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mRZ.\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m word_class:\n\u001b[0;32m     14\u001b[0m     question, answer \u001b[39m=\u001b[39m parse_noun(word_romhead, word_h2)\n",
      "Cell \u001b[1;32mIn[49], line 52\u001b[0m, in \u001b[0;36mparse_verb\u001b[1;34m(word_romhead, word_h2)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_verb\u001b[39m(word_romhead, word_h2):\n\u001b[1;32m---> 52\u001b[0m     translation \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([a\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m word_romhead\u001b[39m.\u001b[39;49mfind(class_\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mfindAll(\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, recursive\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)])\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m  \u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     53\u001b[0m     word_div \u001b[39m=\u001b[39m [\n\u001b[0;32m     54\u001b[0m         div \u001b[39mfor\u001b[39;00m div \u001b[39min\u001b[39;00m word_romhead\u001b[39m.\u001b[39mfindAll(class_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtranslations\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     55\u001b[0m     ][\u001b[39m0\u001b[39m]\n\u001b[0;32m     56\u001b[0m     word \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\n\u001b[0;32m     57\u001b[0m         a\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m word_div\u001b[39m.\u001b[39mfindAll(\n\u001b[0;32m     58\u001b[0m             class_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msource\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     59\u001b[0m         )[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mfindAll([\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstrong\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     60\u001b[0m     ])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'findAll'"
     ]
    }
   ],
   "source": [
    "front, reverse = create_card(word_romheads)\n",
    "print(front)\n",
    "print('-----')\n",
    "print(reverse)\n",
    "print('_________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:07<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "fronts = []\n",
    "reverses = []\n",
    "words = ['Katze', 'Land', 'Tochter', 'Lebensraum', 'Korkenzieher']\n",
    "# words = ['Lebensraum']\n",
    "for word in tqdm(words):\n",
    "    front, reverse = create_card(word)\n",
    "    if front is not None:\n",
    "        fronts.append(front)\n",
    "        reverses.append(reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: przestrzeń życiowa\n",
      "\n",
      "-----\n",
      "der Le̱bensraum, die Le̱bensräume\n",
      "\n",
      "\n",
      "\n",
      "_________\n"
     ]
    }
   ],
   "source": [
    "for front, reverse in zip(fronts, reverses):\n",
    "    print(front)\n",
    "    print('-----')\n",
    "    print(reverse)\n",
    "    print('_________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('eggs.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=';', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    for f, r in zip(fronts, reverses):\n",
    "        spamwriter.writerow([f, r])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
